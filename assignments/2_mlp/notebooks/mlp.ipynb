{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Notebook title -->\n",
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Task Description\n",
    "<!-- \n",
    "- A brief description of the problem you're solving with machine learning.\n",
    "- Define the objective (e.g., classification, regression, clustering, etc.).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 2 types of mulilayer Perceptrons:\n",
    "1. Using only Python. \n",
    "2. Using a high level library\n",
    "\n",
    "* Download the Ecoli dataset: https://archive.ics.uci.edu/ml/datasets/Ecoli\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "* Filter the dataset to include only the classes cp and im, and remove\n",
    "the rest of the data.\n",
    "* Make necessary adjustments to the data to prepare it for the Multi-layer Perceptron models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the MLP from Scratch\n",
    "* Implement a Multilayer Perceptron from scratch using only Python\n",
    "and standard libraries.\n",
    "* Ensure that your implementation includes the following:\n",
    "    * Forward propagation to compute the output.\n",
    "    * Backpropagation to calculate the gradients.\n",
    "    * Weight update mechanism based on the gradients.\n",
    "Note: You do not need to train this model, just ensure the implementation is functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement using a High-Level Library\n",
    "* Implement a Multilayer Perceptron using a high-level library such as PyTorch.\n",
    "* Train the model on the prepared dataset.\n",
    "* Evaluate the model’s performance on a test set using appropriate metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the MLP Implementations\n",
    "* Compare the performance of the MLP implemented from scratch with the one implemented using the high-level library.\n",
    "* Discuss the differences in ease of implementation, training time, and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Instructions\n",
    "* Choose the network architecture with care.\n",
    "* Train and validate all algorithms.\n",
    "* Make the necessary assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Useful Resources\n",
    "<!--\n",
    "- Links to relevant papers, articles, or documentation.\n",
    "- Description of the datasets (if external).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.1 Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.2 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/39/ecoli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imports\n",
    "<!--\n",
    "- Import necessary libraries (e.g., `numpy`, `pandas`, `matplotlib`, `scikit-learn`, etc.).\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ikt450.src.common_imports import *\n",
    "from ikt450.src.config import get_paths\n",
    "from ikt450.src.common_func import load_dataset, save_dataframe, ensure_dir_exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Force CPU for time comparisons\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Global Variables\n",
    "<!--\n",
    "- Define global constants, paths, and configuration settings used throughout the notebook.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM_SEED = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITRATIO = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Function Definitions\n",
    "<!--\n",
    "- Define helper functions that will be used multiple times in the notebook.\n",
    "- Consider organizing these into separate sections (e.g., data processing functions, model evaluation functions).\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse (y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, n_inputs):\n",
    "        self.w = np.random.rand(n_inputs)*0.001\n",
    "        self.b = np.random.rand(1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        x = np.clip(x, -500, 500)  # prevent overflow\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.latest_output = self.sigmoid(np.dot(x, self.w) + self.b)\n",
    "        self.latest_input = x\n",
    "        return self.latest_output\n",
    "    \n",
    "    def backward(self,error,lr):\n",
    "        gradient = error * self.sigmoid_derivative(self.latest_output)\n",
    "        self.w += lr * gradient * self.latest_input\n",
    "        self.b += lr * gradient\n",
    "        return gradient * self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_scratch():\n",
    "    def __init__(self, layer1_size, layer2_size, layer3_size, lr=0.1):\n",
    "        self.lr = lr\n",
    "        self.layer1_size = layer1_size\n",
    "        self.layer2_size = layer2_size\n",
    "        self.layer3_size = layer3_size\n",
    "        self.layer1 = [Perceptron(6) for _ in range(layer1_size)]\n",
    "        self.layer2 = [Perceptron(layer1_size) for _ in range(layer2_size)]\n",
    "        self.layer3 = [Perceptron(layer2_size) for _ in range(layer3_size)]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = np.array(inputs)\n",
    "        \n",
    "        x = []\n",
    "        for l in self.layer1:\n",
    "            x.append(l.forward(inputs))\n",
    "        inputs = np.array(x)\n",
    "        inputs = np.reshape(inputs, (len(inputs)))\n",
    "        \n",
    "        x = []\n",
    "        for l in self.layer2:\n",
    "            x.append(l.forward(inputs))\n",
    "        inputs = np.array(x)\n",
    "        inputs = np.reshape(inputs, (len(inputs)))\n",
    "        x = []\n",
    "        for l in self.layer3:\n",
    "            x.append(l.forward(inputs))\n",
    "        return np.array(x)\n",
    "    \n",
    "    def backward(self,error):\n",
    "        initial_error = error\n",
    "        new_error = []\n",
    "        for l, err in zip(self.layer3,initial_error):\n",
    "            new_error.append(l.backward(err,self.lr))\n",
    "        initial_error = np.array(new_error)\n",
    "        initial_error = np.sum(initial_error, axis=0)\n",
    "        new_error = []\n",
    "        for l, err in zip(self.layer2,initial_error):\n",
    "            new_error.append(l.backward(err,self.lr))\n",
    "        initial_error = np.array(new_error)\n",
    "  \n",
    "        initial_error = np.sum(initial_error, axis=0)\n",
    "    \n",
    "        new_error = []\n",
    "        for l, err in zip(self.layer1,initial_error):\n",
    "            new_error.append(l.backward(err,self.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Torch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_Torch, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. System Setup \n",
    "<!-- (Optional but recommended) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Styling\n",
    "<!--\n",
    "- Set up any visual styles (e.g., for plots).\n",
    "- Configure notebook display settings (e.g., `matplotlib` defaults, pandas display options).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Environment Configuration\n",
    "<!--\n",
    "- Check system dependencies, versions, and ensure reproducibility (e.g., set random seeds).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data loading\n",
    "<!--\n",
    "- Load datasets from files or other sources.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref. [Introduction](#introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is FA0F-7C2E\n",
      "\n",
      " Directory of C:\\Users\\jonin\\Documents\\ikt450\\ikt450\\common\\datasets\n",
      "\n",
      "03.09.2024  21:23    <DIR>          .\n",
      "28.08.2024  02:09    <DIR>          ..\n",
      "03.09.2024  21:22            19�488 ecoli.data\n",
      "03.09.2024  21:22             3�022 ecoli.names\n",
      "23.08.2024  18:45            23�278 pima-indians-diabetes.data.csv\n",
      "               3 File(s)         45�788 bytes\n",
      "               2 Dir(s)  287�257�456�640 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls {paths['PATH_COMMON_DATASETS']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\jonin\\AppData\\Local\\Temp\\ipykernel_165440\\1755953357.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(f\"{paths['PATH_COMMON_DATASETS']}/ecoli.data\",  sep=\"\\s+\", header=None)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{paths['PATH_COMMON_DATASETS']}/ecoli.data\",  sep=\"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data inspection\n",
    "<!--\n",
    "- Preview the data (e.g., `head`, `describe`).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       336 non-null    object \n",
      " 1   1       336 non-null    float64\n",
      " 2   2       336 non-null    float64\n",
      " 3   3       336 non-null    float64\n",
      " 4   4       336 non-null    float64\n",
      " 5   5       336 non-null    float64\n",
      " 6   6       336 non-null    float64\n",
      " 7   7       336 non-null    float64\n",
      " 8   8       336 non-null    object \n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 23.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500060</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495476</td>\n",
       "      <td>0.501488</td>\n",
       "      <td>0.500030</td>\n",
       "      <td>0.500179</td>\n",
       "      <td>0.499732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.194634</td>\n",
       "      <td>0.148157</td>\n",
       "      <td>0.088495</td>\n",
       "      <td>0.027277</td>\n",
       "      <td>0.122376</td>\n",
       "      <td>0.215751</td>\n",
       "      <td>0.209411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.890000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1           2           3           4           5           6  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
       "mean     0.500060    0.500000    0.495476    0.501488    0.500030    0.500179   \n",
       "std      0.194634    0.148157    0.088495    0.027277    0.122376    0.215751   \n",
       "min      0.000000    0.160000    0.480000    0.500000    0.000000    0.030000   \n",
       "25%      0.340000    0.400000    0.480000    0.500000    0.420000    0.330000   \n",
       "50%      0.500000    0.470000    0.480000    0.500000    0.495000    0.455000   \n",
       "75%      0.662500    0.570000    0.480000    0.500000    0.570000    0.710000   \n",
       "max      0.890000    1.000000    1.000000    1.000000    0.880000    1.000000   \n",
       "\n",
       "                7  \n",
       "count  336.000000  \n",
       "mean     0.499732  \n",
       "std      0.209411  \n",
       "min      0.000000  \n",
       "25%      0.350000  \n",
       "50%      0.430000  \n",
       "75%      0.710000  \n",
       "max      0.990000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAT_ECOLI</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEA_ECOLI</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEK_ECOLI</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACKA_ECOLI</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADI_ECOLI</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3    4     5     6     7   8\n",
       "0   AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35  cp\n",
       "1  ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44  cp\n",
       "2  ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46  cp\n",
       "3  ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36  cp\n",
       "4   ADI_ECOLI  0.23  0.32  0.48  0.5  0.55  0.25  0.35  cp"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add code for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Data Cleaning\n",
    "<!--\n",
    "- Handle missing values, outliers, and inconsistencies.\n",
    "- Remove or impute missing data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 NULL, NaN, Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Feature Engineering\n",
    "<!--\n",
    "- Create new features from existing data.\n",
    "- Normalize or standardize features.\n",
    "- Encode categorical variables.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1.1 Feature Selection / Data Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref. [Data Preparation](#data-preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'id', 1: 'mcg', 2: 'gvh', 3: 'lip', 4: 'chg', 5: 'aac', 6: 'alm1', 7: 'alm2', 8: 'class'}, inplace=True)\n",
    "\n",
    "# remove id column\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# keep only the rows with class 'cp' or 'im'\n",
    "df = df[df['class'].isin(['cp', 'im'])]\n",
    "\n",
    "# remove column chg\n",
    "df.drop('chg', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class\n",
    "df['class'] = df['class'].map({'cp': 0, 'im': 1})\n",
    "\n",
    "# split data into X and y\n",
    "X_data = df.drop('class', axis=1)\n",
    "Y_data = df['class']\n",
    "\n",
    "# standardize the data\n",
    "X_data = (X_data - X_data.mean()) / X_data.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=1-SPLITRATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1.2 Target Variable Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Model Selection\n",
    "<!--\n",
    "- Choose the model(s) to be trained (e.g., linear regression, decision trees, neural networks).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref. [Implement the MLP from Scratch](#implement-the-mlp-from-scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_scratch = MLP_scratch(5,5,1, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_torch = MLP_Torch(input_size=X_train.shape[1], hidden_size=5, output_size=1).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "criterion = nn.MSELoss()  # Mean Squared Error \n",
    "optimizer = optim.SGD(m_torch.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Model Training\n",
    "<!--\n",
    "- Train the selected model(s) using the training data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 45.28091456642264\n",
      "Epoch 100 loss: 3.2364459340514267\n",
      "Epoch 200 loss: 2.1941875547139764\n",
      "Epoch 300 loss: 2.0807878494024084\n",
      "Epoch 400 loss: 2.040873179839197\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "t_train_scratch = time.time()\n",
    "for i in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # shuffle the training data\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    for x,y in zip(X_train.values, y_train.values):\n",
    "       \n",
    "        y_pred = m_scratch.forward(x)\n",
    "        \n",
    "        error = y - y_pred\n",
    "        epoch_loss += mse(y, y_pred)\n",
    "       \n",
    "        m_scratch.backward(error)\n",
    "        \n",
    "    # print the loss every 100 epochs 313 \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Epoch {i} loss: {epoch_loss}\")\n",
    "\n",
    "t_train_end_scratch = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.33574435114860535\n",
      "Epoch 100, Loss: 3.564420694601722e-06\n",
      "Epoch 200, Loss: 2.4027640392887406e-06\n",
      "Epoch 300, Loss: 6.1083446780685335e-06\n",
      "Epoch 400, Loss: 2.9451713999151252e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "t_train_torch = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = m_torch(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "t_train_end_torch = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Model Evaluation\n",
    "<!--\n",
    "- Evaluate model performance on validation data.\n",
    "- Use appropriate metrics (e.g., accuracy, precision, recall, RMSE).\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scratch model\n",
    "t_test_scratch = time.time()\n",
    "y_pred_scratch = []\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "loss_scratch = 0\n",
    "\n",
    "for x in X_test.values:\n",
    "    y_pred_scratch.append(m_scratch.forward(x))\n",
    "\n",
    "y_pred_scratch = np.array(y_pred_scratch)\n",
    "y_pred_scratch = np.reshape(y_pred_scratch, (len(y_pred_scratch)))\n",
    "loss_scratch = mse(y_test.values, y_pred_scratch)\n",
    "y_pred_scratch = np.round(y_pred_scratch)\n",
    "TP = np.sum(np.logical_and(y_pred_scratch == 1, y_test.values == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_scratch == 0, y_test.values == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_scratch == 1, y_test.values == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_scratch == 0, y_test.values == 1))\n",
    "\n",
    "f1_score_scratch = 2 * TP / (2 * TP + FP + FN)\n",
    "recall_scratch = TP / (TP + FN)\n",
    "precision_scratch = TP / (TP + FP)\n",
    "accuracy_scratch = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "t_test_end_scratch = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pytorch model\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "t_test_torch = time.time()\n",
    "with torch.no_grad():\n",
    "    predictions = m_torch(X_test_tensor)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = (predictions == y_test_tensor).float().mean()\n",
    "t_test_enc_end_torch = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t | Scratch \t| Torch\n",
      "Train \t | 12.61 s\t| 56.36 s\n",
      "Test  \t | 0.01 s \t| 0.00 s\n",
      "ACC \t | 100.00 % \t| 100.00 %\n",
      "F1 \t | 1.00 \t| 1.00\n",
      "Recall \t | 1.00 \t| 1.00\n",
      "Precision | 1.00 \t| 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t | Scratch \\t| Torch\")\n",
    "print(f\"Train \\t | {t_train_end_scratch - t_train_scratch:.2f} s\\t| {t_train_end_torch - t_train_torch:.2f} s\")\n",
    "print(f\"Test  \\t | {t_test_end_scratch - t_test_scratch:.2f} s \\t| {t_test_enc_end_torch - t_test_torch:.2f} s\")\n",
    "print(f\"ACC \\t | {accuracy_scratch*100:.2f} % \\t| {accuracy.item()*100:.2f} %\")\n",
    "print(f\"F1 \\t | {f1_score_scratch:.2f} \\t| {f1_score(y_test, predictions.cpu()):.2f}\")\n",
    "print(f\"Recall \\t | {recall_scratch:.2f} \\t| {recall_score(y_test, predictions.cpu()):.2f}\")\n",
    "print(f\"Precision | {precision_scratch:.2f} \\t| {precision_score(y_test, predictions.cpu()):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Hyperparameter Tuning\n",
    "<!--\n",
    "- Fine-tune the model using techniques like Grid Search or Random Search.\n",
    "- Evaluate the impact of different hyperparameters.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Model Testing\n",
    "<!--\n",
    "- Evaluate the final model on the test dataset.\n",
    "- Ensure that the model generalizes well to unseen data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Model Interpretation (Optional)\n",
    "<!--\n",
    "- Interpret the model results (e.g., feature importance, SHAP values).\n",
    "- Discuss the strengths and limitations of the model.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Make Predictions\n",
    "<!--\n",
    "- Use the trained model to make predictions on new/unseen data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Save Model and Results\n",
    "<!--\n",
    "- Save the trained model to disk for future use.\n",
    "- Export prediction results for further analysis.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Documentation and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Summary of Findings\n",
    "<!--\n",
    "- Summarize the results and findings of the analysis.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Next Steps\n",
    "<!--\n",
    "- Suggest further improvements, alternative models, or future work.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 References\n",
    "<!--\n",
    "- Cite any resources, papers, or documentation used.\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
