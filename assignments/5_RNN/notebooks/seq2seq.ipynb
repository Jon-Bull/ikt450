{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Notebook title -->\n",
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Task Description\n",
    "<!-- \n",
    "- A brief description of the problem you're solving with machine learning.\n",
    "- Define the objective (e.g., classification, regression, clustering, etc.).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Useful Resources\n",
    "<!--\n",
    "- Links to relevant papers, articles, or documentation.\n",
    "- Description of the datasets (if external).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.1 Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Datasets Kaggle](https://www.kaggle.com/datasets)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A vast repository of datasets across various domains provided by Kaggle, a platform for data science competitions.\n",
    "  \n",
    "* [Toy datasets from Sklearn](https://scikit-learn.org/stable/datasets/toy_dataset.html)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A collection of small datasets that come with the Scikit-learn library, useful for quick prototyping and testing algorithms.\n",
    "  \n",
    "* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A widely-used repository for machine learning datasets, with a variety of real-world datasets available for research and experimentation.\n",
    "  \n",
    "* [Google Dataset Search](https://datasetsearch.research.google.com/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A tool from Google that helps to find datasets stored across the web, with a focus on publicly available data.\n",
    "  \n",
    "* [AWS Public Datasets](https://registry.opendata.aws/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A registry of publicly available datasets that can be analyzed on the cloud using Amazon Web Services (AWS).\n",
    "  \n",
    "* [Microsoft Azure Open Datasets](https://azure.microsoft.com/en-us/services/open-datasets/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A collection of curated datasets from various domains, made available by Microsoft Azure for use in machine learning and analytics.\n",
    "  \n",
    "* [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A GitHub repository that lists a wide variety of datasets across different domains, curated by the community.\n",
    "  \n",
    "* [Data.gov](https://www.data.gov/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A portal to the US government's open data, offering access to a wide range of datasets from various federal agencies.\n",
    "  \n",
    "* [Google BigQuery Public Datasets](https://cloud.google.com/bigquery/public-data)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;Public datasets hosted by Google BigQuery, allowing for quick and powerful querying of large datasets in the cloud.\n",
    "  \n",
    "* [Papers with Code](https://paperswithcode.com/datasets)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A platform that links research papers with the corresponding code and datasets, helping researchers reproduce results and explore new data.\n",
    "  \n",
    "* [Zenodo](https://zenodo.org/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;An open-access repository that allows researchers to share datasets, software, and other research outputs, often linked to academic publications.\n",
    "  \n",
    "* [The World Bank Open Data](https://data.worldbank.org/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A comprehensive source of global development data, with datasets covering various economic and social indicators.\n",
    "  \n",
    "* [OpenML](https://www.openml.org/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;An online platform for sharing datasets, machine learning experiments, and results, fostering collaboration in the ML community.\n",
    "  \n",
    "* [Stanford Large Network Dataset Collection (SNAP)](https://snap.stanford.edu/data/)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A collection of large-scale network datasets from Stanford University, useful for network analysis and graph-based machine learning.\n",
    "  \n",
    "* [KDnuggets Datasets](https://www.kdnuggets.com/datasets/index.html)  \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;A curated list of datasets for data mining and data science, compiled by the KDnuggets community.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.2 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [K-Nearest Neighbors on Kaggle](https://www.kaggle.com/code/mmdatainfo/k-nearest-neighbors)\n",
    "\n",
    "* [Complete Guide to K-Nearest-Neighbors](https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikt450.src.common_imports import *\n",
    "from ikt450.src.config import get_paths\n",
    "from ikt450.src.common_func import load_dataset, save_dataframe, ensure_dir_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITRATIO = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data loading\n",
    "<!--\n",
    "- Load datasets from files or other sources.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(f\"{paths['PATH_COMMON_DATASETS']}/pythonQuestions/Questions.csv\", delimiter=\",\", encoding=\"latin-1\")\n",
    "tags_df = pd.read_csv(f\"{paths['PATH_COMMON_DATASETS']}/pythonQuestions/Tags.csv\", delimiter=\",\", encoding=\"latin-1\")\n",
    "answers_df = pd.read_csv(f\"{paths['PATH_COMMON_DATASETS']}/pythonQuestions/Answers.csv\", delimiter=\",\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1885078 entries, 0 to 1885077\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   Id      int64 \n",
      " 1   Tag     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 28.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 607282 entries, 0 to 607281\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Id            607282 non-null  int64  \n",
      " 1   OwnerUserId   601070 non-null  float64\n",
      " 2   CreationDate  607282 non-null  object \n",
      " 3   Score         607282 non-null  int64  \n",
      " 4   Title         607282 non-null  object \n",
      " 5   Body          607282 non-null  object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 27.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 987122 entries, 0 to 987121\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Id            987122 non-null  int64  \n",
      " 1   OwnerUserId   981755 non-null  float64\n",
      " 2   CreationDate  987122 non-null  object \n",
      " 3   ParentId      987122 non-null  int64  \n",
      " 4   Score         987122 non-null  int64  \n",
      " 5   Body          987122 non-null  object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 45.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tags_df.info())\n",
    "print(questions_df.info())\n",
    "print(answers_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the tags and questions dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = len(list(tags_df[\"Tag\"].unique()))\n",
    "unique_tags = list(tags_df[\"Tag\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16896"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>535</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2008-08-02T18:43:54Z</td>\n",
       "      <td>40</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>&lt;p&gt;I'm starting work on a hobby project with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2008-08-03T01:15:08Z</td>\n",
       "      <td>25</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?</td>\n",
       "      <td>&lt;p&gt;There are several ways to iterate over a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2008-08-03T13:19:16Z</td>\n",
       "      <td>28</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>&lt;p&gt;I don't remember whether I was dreaming or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607277</th>\n",
       "      <td>40143190</td>\n",
       "      <td>333403.0</td>\n",
       "      <td>2016-10-19T23:36:01Z</td>\n",
       "      <td>1</td>\n",
       "      <td>How to execute multiline python code from a ba...</td>\n",
       "      <td>&lt;p&gt;I need to extend a shell script (bash). As ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607278</th>\n",
       "      <td>40143228</td>\n",
       "      <td>6662462.0</td>\n",
       "      <td>2016-10-19T23:40:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>How to get google reCaptcha image source using...</td>\n",
       "      <td>&lt;p&gt;I understood that reCaptcha loads a new fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607279</th>\n",
       "      <td>40143267</td>\n",
       "      <td>4064680.0</td>\n",
       "      <td>2016-10-19T23:44:07Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Updating an ManyToMany field with Django rest</td>\n",
       "      <td>&lt;p&gt;I'm trying to set up this API so I can use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607280</th>\n",
       "      <td>40143338</td>\n",
       "      <td>7044980.0</td>\n",
       "      <td>2016-10-19T23:52:27Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Most possible pairs</td>\n",
       "      <td>&lt;p&gt;Given a list of values, and information on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607281</th>\n",
       "      <td>40143365</td>\n",
       "      <td>4133131.0</td>\n",
       "      <td>2016-10-19T23:55:49Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Theano operations returning odd results</td>\n",
       "      <td>&lt;p&gt;So I'm trying to learn how to use Theano an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607282 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  OwnerUserId          CreationDate  Score  \\\n",
       "0            469        147.0  2008-08-02T15:11:16Z     21   \n",
       "1            502        147.0  2008-08-02T17:01:58Z     27   \n",
       "2            535        154.0  2008-08-02T18:43:54Z     40   \n",
       "3            594        116.0  2008-08-03T01:15:08Z     25   \n",
       "4            683        199.0  2008-08-03T13:19:16Z     28   \n",
       "...          ...          ...                   ...    ...   \n",
       "607277  40143190     333403.0  2016-10-19T23:36:01Z      1   \n",
       "607278  40143228    6662462.0  2016-10-19T23:40:00Z      0   \n",
       "607279  40143267    4064680.0  2016-10-19T23:44:07Z      0   \n",
       "607280  40143338    7044980.0  2016-10-19T23:52:27Z      2   \n",
       "607281  40143365    4133131.0  2016-10-19T23:55:49Z      0   \n",
       "\n",
       "                                                    Title  \\\n",
       "0       How can I find the full path to a font from it...   \n",
       "1                 Get a preview JPEG of a PDF on Windows?   \n",
       "2       Continuous Integration System for a Python Cod...   \n",
       "3          cx_Oracle: How do I iterate over a result set?   \n",
       "4       Using 'in' to match an attribute of Python obj...   \n",
       "...                                                   ...   \n",
       "607277  How to execute multiline python code from a ba...   \n",
       "607278  How to get google reCaptcha image source using...   \n",
       "607279      Updating an ManyToMany field with Django rest   \n",
       "607280                                Most possible pairs   \n",
       "607281            Theano operations returning odd results   \n",
       "\n",
       "                                                     Body  \n",
       "0       <p>I am using the Photoshop's javascript API t...  \n",
       "1       <p>I have a cross-platform (Python) applicatio...  \n",
       "2       <p>I'm starting work on a hobby project with a...  \n",
       "3       <p>There are several ways to iterate over a re...  \n",
       "4       <p>I don't remember whether I was dreaming or ...  \n",
       "...                                                   ...  \n",
       "607277  <p>I need to extend a shell script (bash). As ...  \n",
       "607278  <p>I understood that reCaptcha loads a new fra...  \n",
       "607279  <p>I'm trying to set up this API so I can use ...  \n",
       "607280  <p>Given a list of values, and information on ...  \n",
       "607281  <p>So I'm trying to learn how to use Theano an...  \n",
       "\n",
       "[607282 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_grouped = tags_df.groupby('Id')['Tag'].apply(list).reset_index(name='Tags')\n",
    "questions_and_tags_df = questions_df.merge(tags_grouped,on=\"Id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_answer</th>\n",
       "      <th>OwnerUserId_answer</th>\n",
       "      <th>CreationDate_answer</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Score_answer</th>\n",
       "      <th>Body_answer</th>\n",
       "      <th>Id_question</th>\n",
       "      <th>OwnerUserId_question</th>\n",
       "      <th>CreationDate_question</th>\n",
       "      <th>Score_question</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body_question</th>\n",
       "      <th>Tags_answer</th>\n",
       "      <th>Id</th>\n",
       "      <th>Tags_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>497</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2008-08-02T16:56:53Z</td>\n",
       "      <td>469</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;open up a terminal (Applications-&amp;gt;Utilit...</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "      <td>469</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2008-08-02T17:42:28Z</td>\n",
       "      <td>469</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I haven't been able to find anything that d...</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "      <td>469</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3040</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2008-08-06T03:01:23Z</td>\n",
       "      <td>469</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;p&gt;Unfortunately the only API that isn't depre...</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "      <td>469</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195170</td>\n",
       "      <td>745.0</td>\n",
       "      <td>2008-10-12T07:02:40Z</td>\n",
       "      <td>469</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;There must be a method in Cocoa to get a li...</td>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "      <td>469</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2008-08-02T18:49:07Z</td>\n",
       "      <td>502</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;p&gt;You can use ImageMagick's convert utility f...</td>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>[python, windows, image, pdf]</td>\n",
       "      <td>502</td>\n",
       "      <td>[python, windows, image, pdf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987117</th>\n",
       "      <td>40143239</td>\n",
       "      <td>6640099.0</td>\n",
       "      <td>2016-10-19T23:41:38Z</td>\n",
       "      <td>40142731</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;Well there are many different ways to detec...</td>\n",
       "      <td>40142731</td>\n",
       "      <td>6875348.0</td>\n",
       "      <td>2016-10-19T22:46:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Collision Between two sprites - Python 3.5.2</td>\n",
       "      <td>&lt;p&gt;I have an image of a ufo and a missile. I'm...</td>\n",
       "      <td>[python, pygame, collision-detection]</td>\n",
       "      <td>40142731</td>\n",
       "      <td>[python, pygame, collision-detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987118</th>\n",
       "      <td>40143315</td>\n",
       "      <td>3125566.0</td>\n",
       "      <td>2016-10-19T23:49:43Z</td>\n",
       "      <td>40143166</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;First thing, you should use &lt;code&gt;if/elif&lt;/...</td>\n",
       "      <td>40143166</td>\n",
       "      <td>7044992.0</td>\n",
       "      <td>2016-10-19T23:33:31Z</td>\n",
       "      <td>1</td>\n",
       "      <td>finding cubed root using delta and epsilon in ...</td>\n",
       "      <td>&lt;p&gt;I am trying to write a program that finds c...</td>\n",
       "      <td>[python, python-3.x]</td>\n",
       "      <td>40143166</td>\n",
       "      <td>[python, python-3.x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987119</th>\n",
       "      <td>40143317</td>\n",
       "      <td>2350575.0</td>\n",
       "      <td>2016-10-19T23:50:04Z</td>\n",
       "      <td>40142194</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;If you are using firefox ver &gt;47.0.1 you ne...</td>\n",
       "      <td>40142194</td>\n",
       "      <td>7044759.0</td>\n",
       "      <td>2016-10-19T21:58:32Z</td>\n",
       "      <td>1</td>\n",
       "      <td>errors with webdriver.Firefox() with selenium</td>\n",
       "      <td>&lt;p&gt;I am using python 3.5, firefox 45 (also tri...</td>\n",
       "      <td>[python, selenium, firefox]</td>\n",
       "      <td>40142194</td>\n",
       "      <td>[python, selenium, firefox]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987120</th>\n",
       "      <td>40143349</td>\n",
       "      <td>6934347.0</td>\n",
       "      <td>2016-10-19T23:54:02Z</td>\n",
       "      <td>40077010</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;I solved my own problem defining the follow...</td>\n",
       "      <td>40077010</td>\n",
       "      <td>6934347.0</td>\n",
       "      <td>2016-10-17T00:33:51Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Can't pass random variable to tf.image.central...</td>\n",
       "      <td>&lt;p&gt;In Tensorflow I am training from a set of P...</td>\n",
       "      <td>[python, tensorflow]</td>\n",
       "      <td>40077010</td>\n",
       "      <td>[python, tensorflow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987121</th>\n",
       "      <td>40143370</td>\n",
       "      <td>6502500.0</td>\n",
       "      <td>2016-10-19T23:56:31Z</td>\n",
       "      <td>40142538</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;I can't seem to reproduce your error but up...</td>\n",
       "      <td>40142538</td>\n",
       "      <td>5992039.0</td>\n",
       "      <td>2016-10-19T22:28:03Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Scrapy spider for JSON response is giving me e...</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;import json\\nimport scrapy\\n\\nclass...</td>\n",
       "      <td>[python, json, python-2.7, scrapy, scrapy-spider]</td>\n",
       "      <td>40142538</td>\n",
       "      <td>[python, json, python-2.7, scrapy, scrapy-spider]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987122 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id_answer  OwnerUserId_answer   CreationDate_answer  ParentId  \\\n",
       "0             497                50.0  2008-08-02T16:56:53Z       469   \n",
       "1             518               153.0  2008-08-02T17:42:28Z       469   \n",
       "2            3040               457.0  2008-08-06T03:01:23Z       469   \n",
       "3          195170               745.0  2008-10-12T07:02:40Z       469   \n",
       "4             536               161.0  2008-08-02T18:49:07Z       502   \n",
       "...           ...                 ...                   ...       ...   \n",
       "987117   40143239           6640099.0  2016-10-19T23:41:38Z  40142731   \n",
       "987118   40143315           3125566.0  2016-10-19T23:49:43Z  40143166   \n",
       "987119   40143317           2350575.0  2016-10-19T23:50:04Z  40142194   \n",
       "987120   40143349           6934347.0  2016-10-19T23:54:02Z  40077010   \n",
       "987121   40143370           6502500.0  2016-10-19T23:56:31Z  40142538   \n",
       "\n",
       "        Score_answer                                        Body_answer  \\\n",
       "0                  4  <p>open up a terminal (Applications-&gt;Utilit...   \n",
       "1                  2  <p>I haven't been able to find anything that d...   \n",
       "2                 12  <p>Unfortunately the only API that isn't depre...   \n",
       "3                  1  <p>There must be a method in Cocoa to get a li...   \n",
       "4                  9  <p>You can use ImageMagick's convert utility f...   \n",
       "...              ...                                                ...   \n",
       "987117             2  <p>Well there are many different ways to detec...   \n",
       "987118             2  <p>First thing, you should use <code>if/elif</...   \n",
       "987119             0  <p>If you are using firefox ver >47.0.1 you ne...   \n",
       "987120             0  <p>I solved my own problem defining the follow...   \n",
       "987121             0  <p>I can't seem to reproduce your error but up...   \n",
       "\n",
       "        Id_question  OwnerUserId_question CreationDate_question  \\\n",
       "0               469                 147.0  2008-08-02T15:11:16Z   \n",
       "1               469                 147.0  2008-08-02T15:11:16Z   \n",
       "2               469                 147.0  2008-08-02T15:11:16Z   \n",
       "3               469                 147.0  2008-08-02T15:11:16Z   \n",
       "4               502                 147.0  2008-08-02T17:01:58Z   \n",
       "...             ...                   ...                   ...   \n",
       "987117     40142731             6875348.0  2016-10-19T22:46:59Z   \n",
       "987118     40143166             7044992.0  2016-10-19T23:33:31Z   \n",
       "987119     40142194             7044759.0  2016-10-19T21:58:32Z   \n",
       "987120     40077010             6934347.0  2016-10-17T00:33:51Z   \n",
       "987121     40142538             5992039.0  2016-10-19T22:28:03Z   \n",
       "\n",
       "        Score_question                                              Title  \\\n",
       "0                   21  How can I find the full path to a font from it...   \n",
       "1                   21  How can I find the full path to a font from it...   \n",
       "2                   21  How can I find the full path to a font from it...   \n",
       "3                   21  How can I find the full path to a font from it...   \n",
       "4                   27            Get a preview JPEG of a PDF on Windows?   \n",
       "...                ...                                                ...   \n",
       "987117               0       Collision Between two sprites - Python 3.5.2   \n",
       "987118               1  finding cubed root using delta and epsilon in ...   \n",
       "987119               1      errors with webdriver.Firefox() with selenium   \n",
       "987120               2  Can't pass random variable to tf.image.central...   \n",
       "987121               0  Scrapy spider for JSON response is giving me e...   \n",
       "\n",
       "                                            Body_question  \\\n",
       "0       <p>I am using the Photoshop's javascript API t...   \n",
       "1       <p>I am using the Photoshop's javascript API t...   \n",
       "2       <p>I am using the Photoshop's javascript API t...   \n",
       "3       <p>I am using the Photoshop's javascript API t...   \n",
       "4       <p>I have a cross-platform (Python) applicatio...   \n",
       "...                                                   ...   \n",
       "987117  <p>I have an image of a ufo and a missile. I'm...   \n",
       "987118  <p>I am trying to write a program that finds c...   \n",
       "987119  <p>I am using python 3.5, firefox 45 (also tri...   \n",
       "987120  <p>In Tensorflow I am training from a set of P...   \n",
       "987121  <pre><code>import json\\nimport scrapy\\n\\nclass...   \n",
       "\n",
       "                                              Tags_answer        Id  \\\n",
       "0                         [python, osx, fonts, photoshop]       469   \n",
       "1                         [python, osx, fonts, photoshop]       469   \n",
       "2                         [python, osx, fonts, photoshop]       469   \n",
       "3                         [python, osx, fonts, photoshop]       469   \n",
       "4                           [python, windows, image, pdf]       502   \n",
       "...                                                   ...       ...   \n",
       "987117              [python, pygame, collision-detection]  40142731   \n",
       "987118                               [python, python-3.x]  40143166   \n",
       "987119                        [python, selenium, firefox]  40142194   \n",
       "987120                               [python, tensorflow]  40077010   \n",
       "987121  [python, json, python-2.7, scrapy, scrapy-spider]  40142538   \n",
       "\n",
       "                                            Tags_question  \n",
       "0                         [python, osx, fonts, photoshop]  \n",
       "1                         [python, osx, fonts, photoshop]  \n",
       "2                         [python, osx, fonts, photoshop]  \n",
       "3                         [python, osx, fonts, photoshop]  \n",
       "4                           [python, windows, image, pdf]  \n",
       "...                                                   ...  \n",
       "987117              [python, pygame, collision-detection]  \n",
       "987118                               [python, python-3.x]  \n",
       "987119                        [python, selenium, firefox]  \n",
       "987120                               [python, tensorflow]  \n",
       "987121  [python, json, python-2.7, scrapy, scrapy-spider]  \n",
       "\n",
       "[987122 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_and_questions_df = answers_df.merge(questions_and_tags_df, left_on=\"ParentId\", right_on=\"Id\", suffixes=('_answer', '_question'))\n",
    "answers_and_questions_df\n",
    "# merge the answers and questions with tags dataframes\n",
    "answers_and_questions_df = answers_and_questions_df.merge(tags_grouped, left_on=\"ParentId\", right_on=\"Id\", suffixes=('_answer', '_question'))\n",
    "answers_and_questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_answer</th>\n",
       "      <th>Body_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;open up a terminal (Applications-&amp;gt;Utilit...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;I haven't been able to find anything that d...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;Unfortunately the only API that isn't depre...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;There must be a method in Cocoa to get a li...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;You can use ImageMagick's convert utility f...</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987117</th>\n",
       "      <td>&lt;p&gt;Well there are many different ways to detec...</td>\n",
       "      <td>&lt;p&gt;I have an image of a ufo and a missile. I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987118</th>\n",
       "      <td>&lt;p&gt;First thing, you should use &lt;code&gt;if/elif&lt;/...</td>\n",
       "      <td>&lt;p&gt;I am trying to write a program that finds c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987119</th>\n",
       "      <td>&lt;p&gt;If you are using firefox ver &gt;47.0.1 you ne...</td>\n",
       "      <td>&lt;p&gt;I am using python 3.5, firefox 45 (also tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987120</th>\n",
       "      <td>&lt;p&gt;I solved my own problem defining the follow...</td>\n",
       "      <td>&lt;p&gt;In Tensorflow I am training from a set of P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987121</th>\n",
       "      <td>&lt;p&gt;I can't seem to reproduce your error but up...</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;import json\\nimport scrapy\\n\\nclass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Body_answer  \\\n",
       "0       <p>open up a terminal (Applications-&gt;Utilit...   \n",
       "1       <p>I haven't been able to find anything that d...   \n",
       "2       <p>Unfortunately the only API that isn't depre...   \n",
       "3       <p>There must be a method in Cocoa to get a li...   \n",
       "4       <p>You can use ImageMagick's convert utility f...   \n",
       "...                                                   ...   \n",
       "987117  <p>Well there are many different ways to detec...   \n",
       "987118  <p>First thing, you should use <code>if/elif</...   \n",
       "987119  <p>If you are using firefox ver >47.0.1 you ne...   \n",
       "987120  <p>I solved my own problem defining the follow...   \n",
       "987121  <p>I can't seem to reproduce your error but up...   \n",
       "\n",
       "                                            Body_question  \n",
       "0       <p>I am using the Photoshop's javascript API t...  \n",
       "1       <p>I am using the Photoshop's javascript API t...  \n",
       "2       <p>I am using the Photoshop's javascript API t...  \n",
       "3       <p>I am using the Photoshop's javascript API t...  \n",
       "4       <p>I have a cross-platform (Python) applicatio...  \n",
       "...                                                   ...  \n",
       "987117  <p>I have an image of a ufo and a missile. I'm...  \n",
       "987118  <p>I am trying to write a program that finds c...  \n",
       "987119  <p>I am using python 3.5, firefox 45 (also tri...  \n",
       "987120  <p>In Tensorflow I am training from a set of P...  \n",
       "987121  <pre><code>import json\\nimport scrapy\\n\\nclass...  \n",
       "\n",
       "[987122 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the columns we need\n",
    "# answers body and tag\n",
    "answers_and_questions_df = answers_and_questions_df[[\"Body_answer\", \"Body_question\"]]\n",
    "answers_and_questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers_and_questions_df = answers_and_questions_df[:20000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonin\\AppData\\Local\\Temp\\ipykernel_52000\\2684365328.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answers_and_questions_df['Body_question'] = answers_and_questions_df['Body_question'].apply(preprocess_text)\n",
      "C:\\Users\\jonin\\AppData\\Local\\Temp\\ipykernel_52000\\2684365328.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answers_and_questions_df['Body_answer'] = answers_and_questions_df['Body_answer'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove leading <p> tags\n",
    "    text = re.sub(r'^<p>', '', text)\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize, remove stopwords, then lemmatize words\n",
    "    text = \" \".join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "answers_and_questions_df['Body_question'] = answers_and_questions_df['Body_question'].apply(preprocess_text)\n",
    "answers_and_questions_df['Body_answer'] = answers_and_questions_df['Body_answer'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_answer</th>\n",
       "      <th>Body_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open up a terminal applicationsgtutilitiesgtte...</td>\n",
       "      <td>i am using the photoshops javascript api to fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i havent been able to find anything that doe t...</td>\n",
       "      <td>i am using the photoshops javascript api to fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unfortunately the only api that isnt deprecate...</td>\n",
       "      <td>i am using the photoshops javascript api to fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there must be a method in cocoa to get a list ...</td>\n",
       "      <td>i am using the photoshops javascript api to fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you can use imagemagicks convert utility for t...</td>\n",
       "      <td>i have a crossplatform python application whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>to find the load path of module already loaded...</td>\n",
       "      <td>how can i get the file path of a module import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i have been using this method which applies to...</td>\n",
       "      <td>how can i get the file path of a module import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>in this simple case the easiest way is to just...</td>\n",
       "      <td>im trying to use scons to build a latex docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>something along these line should do p precode...</td>\n",
       "      <td>im trying to use scons to build a latex docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>yes and no the fk relationship is described at...</td>\n",
       "      <td>is there any way to set a foreign key in djang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Body_answer  \\\n",
       "0      open up a terminal applicationsgtutilitiesgtte...   \n",
       "1      i havent been able to find anything that doe t...   \n",
       "2      unfortunately the only api that isnt deprecate...   \n",
       "3      there must be a method in cocoa to get a list ...   \n",
       "4      you can use imagemagicks convert utility for t...   \n",
       "...                                                  ...   \n",
       "19995  to find the load path of module already loaded...   \n",
       "19996  i have been using this method which applies to...   \n",
       "19997  in this simple case the easiest way is to just...   \n",
       "19998  something along these line should do p precode...   \n",
       "19999  yes and no the fk relationship is described at...   \n",
       "\n",
       "                                           Body_question  \n",
       "0      i am using the photoshops javascript api to fi...  \n",
       "1      i am using the photoshops javascript api to fi...  \n",
       "2      i am using the photoshops javascript api to fi...  \n",
       "3      i am using the photoshops javascript api to fi...  \n",
       "4      i have a crossplatform python application whic...  \n",
       "...                                                  ...  \n",
       "19995  how can i get the file path of a module import...  \n",
       "19996  how can i get the file path of a module import...  \n",
       "19997  im trying to use scons to build a latex docume...  \n",
       "19998  im trying to use scons to build a latex docume...  \n",
       "19999  is there any way to set a foreign key in djang...  \n",
       "\n",
       "[19999 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_and_questions_df\n",
    "\n",
    "# drop rows with empty strings and duplicates for any row\n",
    "answers_and_questions_df = answers_and_questions_df.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "answers_and_questions_df = answers_and_questions_df.dropna()\n",
    "answers_and_questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "# Set threshold for minimum word frequency\n",
    "min_freq = 1  # or a suitable value based on your data\n",
    "max_length = 15  # Maximum sequence length\n",
    "\n",
    "# Step 1: Tokenize and Build Vocabulary with a Frequency Filter\n",
    "tokenized_texts = answers_and_questions_df['Body_answer'].apply(lambda x: x.split())\n",
    "word_counts = Counter(chain(*tokenized_texts))\n",
    "\n",
    "# Build vocabulary with words meeting the min frequency requirement\n",
    "vocab = {word: idx + 2 for idx, (word, count) in enumerate(word_counts.items()) if count >= min_freq}  # Start at 2\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = 1  # Unknown token for rare words\n",
    "vocab['<EOS>'] = 2\n",
    "\n",
    "# Step 2: Encode Texts with Unknown Token Handling\n",
    "answers_and_questions_df['encoded_text'] = tokenized_texts.apply(\n",
    "    lambda x: [vocab.get(word, vocab['<UNK>']) for word in x]  # Use <UNK> for words not in vocab\n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Pad or Truncate Sequences\n",
    "answers_and_questions_df['padded_text'] = answers_and_questions_df['encoded_text'].apply(\n",
    "    lambda x: x[:max_length] + [vocab['<PAD>']] * (max_length - len(x)) if len(x) < max_length else x[:max_length]\n",
    ")\n",
    "answers_and_questions_df['padded_text'] = answers_and_questions_df['padded_text'].apply(lambda x: x + [vocab[\"<EOS>\"]])\n",
    "# Convert to tensor\n",
    "y = torch.tensor(answers_and_questions_df['padded_text'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenize and Build Vocabulary with a Frequency Filter\n",
    "tokenized_texts = answers_and_questions_df['Body_question'].apply(lambda x: x.split())\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Encode Texts with Unknown Token Handling\n",
    "answers_and_questions_df['encoded_text'] = tokenized_texts.apply(\n",
    "    lambda x: [vocab.get(word, vocab['<UNK>']) for word in x]  # Use <UNK> for words not in vocab\n",
    ")\n",
    "\n",
    "# Step 3: Pad or Truncate Sequences\n",
    "answers_and_questions_df['padded_text'] = answers_and_questions_df['encoded_text'].apply(\n",
    "    lambda x: x[:max_length] + [vocab['<PAD>']] * (max_length - len(x)) if len(x) < max_length else x[:max_length]\n",
    ")\n",
    "\n",
    "# add EOS token\n",
    "answers_and_questions_df['padded_text'] = answers_and_questions_df['padded_text'].apply(lambda x: x + [vocab[\"<EOS>\"]])\n",
    "# Convert to tensor\n",
    "x = torch.tensor(answers_and_questions_df['padded_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141279"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max value in x\n",
    "max_value = x.max().item()\n",
    "max_value\n",
    "\n",
    "invalid_indices = x >= len(vocab)\n",
    "if invalid_indices.any():\n",
    "    print(f\"Found {invalid_indices.sum().item()} invalid indices, setting them to '<UNK>' token.\")\n",
    "    x[invalid_indices] = vocab['<UNK>']\n",
    "\n",
    "max_value = x.max().item()\n",
    "max_value\n",
    "\n",
    "# find max value in y\n",
    "max_value = y.max().item()\n",
    "max_value\n",
    "\n",
    "invalid_indices = y >= len(vocab)\n",
    "if invalid_indices.any():\n",
    "    print(f\"Found {invalid_indices.sum().item()} invalid indices, setting them to '<UNK>' token.\")\n",
    "    y[invalid_indices] = vocab['<UNK>']\n",
    "\n",
    "max_value = y.max().item()\n",
    "max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141290"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15999, 16]),\n",
       " torch.Size([4000, 16]),\n",
       " torch.Size([15999, 16]),\n",
       " torch.Size([4000, 16]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, y\n",
    "del answers_and_questions_df\n",
    "del tokenized_texts\n",
    "\n",
    "del tags_df\n",
    "del questions_df\n",
    "del answers_df\n",
    "del tags_grouped\n",
    "del questions_and_tags_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 'unique_tags' is 135224 bytes in memory.\n",
      "Variable '_10' is 987135972 bytes in memory.\n",
      "Variable '_12' is 2579456964 bytes in memory.\n",
      "Variable '_13' is 2075577061 bytes in memory.\n",
      "Variable 'stop_words' is 8408 bytes in memory.\n",
      "Variable '_16' is 51960177 bytes in memory.\n",
      "Variable 'word_counts' is 5242984 bytes in memory.\n",
      "Variable 'vocab' is 5242968 bytes in memory.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def print_large_items(locals_dict, size_threshold=1024):\n",
    "    \"\"\"\n",
    "    Prints variables from the given dictionary that are above the specified size threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - locals_dict: dict, the dictionary of variables to inspect, typically locals() or globals().\n",
    "    - size_threshold: int, the size in bytes above which variables should be printed.\n",
    "    \"\"\"\n",
    "    for var_name, var_value in locals_dict.items():\n",
    "        var_size = sys.getsizeof(var_value)\n",
    "        if var_size > size_threshold:\n",
    "            print(f\"Variable '{var_name}' is {var_size} bytes in memory.\")\n",
    "\n",
    "# Usage example\n",
    "# Assuming you call this function in the scope where your variables are defined\n",
    "print_large_items(locals(), size_threshold=5000)  # Adjust threshold as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Data Cleaning\n",
    "<!--\n",
    "- Handle missing values, outliers, and inconsistencies.\n",
    "- Remove or impute missing data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 NULL, NaN, Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Feature Engineering\n",
    "<!--\n",
    "- Create new features from existing data.\n",
    "- Normalize or standardize features.\n",
    "- Encode categorical variables.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1.1 Feature Selection / Data Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>What does it?</summary>\n",
    "<br>\n",
    "This line removes the `` column from the DataFrame `df` and assigns the remaining columns to `X`.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Why do we do it?</summary>\n",
    "<br>\n",
    "We do this to separate the input features (which are stored in `X`) from the target variable (which will be stored in `y`). This separation is essential in supervised learning tasks where the goal is to predict the target variable based on the input features.\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1.3 Feature Scaling / Standardization / Z-score Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>What does it?</summary>\n",
    "<br>\n",
    "This line standardizes the features in `X` by subtracting the mean of each feature and dividing by the standard deviation of that feature. This transforms the data so that each feature has a mean of 0 and a standard deviation of 1.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Why do we do it?</summary>\n",
    "<br>\n",
    "Standardization is crucial when using machine learning algorithms that rely on distance calculations (like K-Nearest Neighbors, SVM, or Neural Networks). Without standardization, features with larger scales could dominate the distance calculation, leading to biased model behavior. By standardizing, all features contribute equally to the model, regardless of their original scale.\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Data Splitting\n",
    "<!--\n",
    "- Split data into training, validation, and test sets.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq Model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "\n",
    "    # Example in the forward method\n",
    "    def forward(self, x, hidden):\n",
    "        # Embed the input sequence\n",
    "        x = self.encoder(x)\n",
    "      #  print(\"Encoder output shape:\", x.shape)  # Add this line\n",
    "\n",
    "        # Ensure x has dimensions (batch_size, sequence_length, embedding_dim)\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "     #   print(\"GRU output shape:\", output.shape)  # Add this line\n",
    "\n",
    "        output = self.dropout(output)\n",
    "    #    print(\"Output after dropout shape:\", output.shape)  # Add this line\n",
    "\n",
    "        # Pass the output through the decoder layer and reshape as necessary\n",
    "        output = self.decoder(output)\n",
    "   #     print(\"Decoder output shape:\", output.shape)  # Add this line\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "       return torch.zeros(self.gru.num_layers, batch_size, self.gru.hidden_size)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.39327209186554\n",
      "Epoch 2, Loss: 5.600018615722656\n",
      "Epoch 3, Loss: 5.244165034294128\n",
      "Epoch 4, Loss: 4.972579601287841\n",
      "Epoch 5, Loss: 4.736355346679687\n"
     ]
    }
   ],
   "source": [
    "# Training the Seq2Seq Model\n",
    "model = Seq2Seq(vocab_size=len(vocab), embedding_dim=100, hidden_dim=256, output_dim=len(vocab), n_layers=1, dropout=0.5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for questions, answers in train_loader:  # data_loader gives pairs of questions and corresponding answers\n",
    "        # Send questions and answers to GPU\n",
    "        questions = questions.to(device)\n",
    "        answers = answers.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "\n",
    "        # Forward pass for the whole sequence, using teacher forcing\n",
    "        hidden = model.init_hidden(questions.size(0)).to(device)\n",
    "        \n",
    "        encoder_outputs, hidden = model(questions, hidden)  # forward pass through encoder\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        # calculate loss for first token\n",
    "       # encoder_outputs = encoder_outputs.view(-1, encoder_outputs.shape[-1])\n",
    "        target = answers[:, 0]\n",
    "        encoder_outputs = encoder_outputs[:, -1, :]\n",
    "\n",
    "        loss += criterion(encoder_outputs, target)\n",
    "\n",
    "\n",
    "        # Teacher-forcing loop over answer sequence\n",
    "        for i in range(1,answers.size(1)-1):  # Iterating over answer length\n",
    "            input_token = answers[:, i].unsqueeze(1)  # Extract and add a dimension for embedding\n",
    "     \n",
    "\n",
    "            # Forward pass for each time step\n",
    "            output, hidden = model(input_token, hidden)  # input is answer token at each time step\n",
    "\n",
    "            # Reshape output to match expected input for CrossEntropyLoss\n",
    "            output = output.view(-1, output.shape[-1])  \n",
    "            target = answers[:, i+1]\n",
    "\n",
    "            # Calculate loss for this time step\n",
    "            loss += criterion(output, target)\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Optimization step\n",
    "        total_loss += loss.item() / answers.size(1)  # Average over sequence length\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.06751475524902344\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "model.eval()\n",
    "loss_total = 0\n",
    "with torch.no_grad():\n",
    "    for questions, answers in test_loader:\n",
    "        questions = questions.to(device)\n",
    "        answers = answers.to(device)\n",
    "        hidden = model.init_hidden(questions.size(0))\n",
    "        output, hidden = model(questions, hidden)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = answers.view(-1)\n",
    "        loss = criterion(output, target)\n",
    "        loss_total += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {loss.item() / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 967,  454,   33, 1261,    4,   99,   89,  702,  213,    4,  548,   89,\n",
       "           21,  702,    0,    2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_text = \"How do I sort a list of dictionaries by a value of the dictionary?\"\n",
    "# Preprocess the question text\n",
    "question_text = preprocess_text(question_text)\n",
    "# Tokenize the question text\n",
    "question_tokens = [vocab.get(word, vocab['<UNK>']) for word in question_text.split()]\n",
    "# Pad the question text\n",
    "question_tokens = question_tokens[:max_length] + [vocab['<PAD>']] * (max_length - len(question_tokens))\n",
    "# Convert to tensor\n",
    "# add EOS token\n",
    "question_tokens = question_tokens + [vocab[\"<EOS>\"]]\n",
    "\n",
    "question_tensor = torch.tensor(question_tokens).unsqueeze(0).to(device)\n",
    "# Initialize hidden state\n",
    "hidden = model.init_hidden(1)\n",
    "question_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 23,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 33])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with no gradient calculation\n",
    "hidden = model.init_hidden(1).to(device)  # Initialize hidden state for batch size 1\n",
    "question_tensor = question_tensor.to(device)  # Ensure question tensor is on the same device\n",
    "\n",
    "output_sequence = []  # List to store output tokens\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(answers.size(1)):  # Iterating over the answer sequence length\n",
    "        # Forward pass through the model\n",
    "        output, hidden = model(question_tensor, hidden)\n",
    "        \n",
    "        # Reshape output and find the most likely token for this time step\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        predicted_token = torch.argmax(output, dim=1)\n",
    "        \n",
    "        # Print or store the predicted token for each batch element individually\n",
    "        \n",
    "        output_sequence.extend(predicted_token.cpu().numpy().tolist())  # Append tokens as a list\n",
    "        \n",
    "        # Optionally, update question_tensor to the predicted token for auto-regressive testing\n",
    "        question_tensor = predicted_token.unsqueeze(0)  # Reshape for next time step if needed\n",
    "        \n",
    "        # Exit after the first time step for debugging purposes (remove break to run full sequence)\n",
    "        break\n",
    "\n",
    "# Final output after one time step or full sequence\n",
    "final_output = torch.tensor(output_sequence)\n",
    "final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to you i'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_indices = final_output.tolist()\n",
    "# remove the <EOS> and <PAD> tokens and any tokens after <EOS> or <PAD>\n",
    "predicted_indices = [idx for idx in predicted_indices if idx not in [vocab[\"<EOS>\"], vocab[\"<PAD>\"]]]\n",
    "\n",
    "predicted_answer = [word for idx in predicted_indices for word, word_idx in vocab.items() if word_idx == idx]\n",
    "predicted_answer = \" \".join(predicted_answer)\n",
    "predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a hrefhttpdocsbinstarorgdraftexampleshtmlsubmitabuildfromgithub relnofollowbinstara for a list of the list of the list the\n",
      "\n",
      "a look at a a answera of the a recent module a you\n",
      "\n",
      "i have a good difference between the a function in python and i\n",
      "\n",
      "you can use a a hrefhttpenwikipediaorgwikipython_28programming_language29pythona a a relnofollowrequestsa a a you want to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question_text = input(predicted_answer)\n",
    "\n",
    "    if question_text.lower() == 'exit':\n",
    "        break\n",
    "    # Preprocess the question text\n",
    "    question_text = preprocess_text(question_text)\n",
    "    # Tokenize the question text\n",
    "    question_tokens = [vocab.get(word, vocab['<UNK>']) for word in question_text.split()]\n",
    "    # Pad the question text\n",
    "    question_tokens = question_tokens[:max_length] + [vocab['<PAD>']] * (max_length - len(question_tokens))\n",
    "    # Convert to tensor\n",
    "    # add EOS token\n",
    "    question_tokens = question_tokens + [vocab[\"<EOS>\"]]\n",
    "\n",
    "    question_tensor = torch.tensor(question_tokens).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "\n",
    "     # Testing with no gradient calculation\n",
    "    hidden = model.init_hidden(1).to(device)  # Initialize hidden state for batch size 1\n",
    "    question_tensor = question_tensor.to(device)  # Ensure question tensor is on the same device\n",
    "    \n",
    "    output_sequence = []  # List to store output tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(15):  # Iterating over the answer sequence length\n",
    "            # Forward pass through the model\n",
    "        \n",
    "    #    print(question_tensor)\n",
    "            # reshape question tensor\n",
    "            question_tensor = question_tensor.view(1, -1)\n",
    "            output, hidden = model(question_tensor, hidden)\n",
    "\n",
    "            \n",
    "            \n",
    "            # Reshape output and find the most likely token for this time step\n",
    "            output = output[0, -1, :]\n",
    "     #       print(output.shape)\n",
    "            predicted_token = torch.argmax(output, dim=0)\n",
    "            \n",
    "            # Print or store the predicted token for each batch element individually\n",
    "      #      print(predicted_token)\n",
    "           \n",
    "            output_sequence.append(predicted_token)  # Append tokens as a list\n",
    "            \n",
    "            # Optionally, update question_tensor to the predicted token for auto-regressive testing\n",
    "            question_tensor = predicted_token  # Reshape for next time step if needed\n",
    "            \n",
    "            # Exit after the first time step for debugging purposes (remove break to run full sequence)\n",
    "        \n",
    "\n",
    "    # Final output after one time step or full sequence\n",
    "    final_output = torch.tensor(output_sequence)\n",
    "    final_output\n",
    "\n",
    "    predicted_indices = final_output.tolist()\n",
    "    # remove the <EOS> and <PAD> tokens and any tokens after <EOS> or <PAD>\n",
    "    predicted_indices = [idx for idx in predicted_indices if idx not in [vocab[\"<EOS>\"], vocab[\"<PAD>\"]]]\n",
    "\n",
    "    predicted_answer = [word for idx in predicted_indices for word, word_idx in vocab.items() if word_idx == idx]\n",
    "    predicted_answer = \" \".join(predicted_answer)\n",
    "    predicted_answer\n",
    "    print(predicted_answer)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Model Selection\n",
    "<!--\n",
    "- Choose the model(s) to be trained (e.g., linear regression, decision trees, neural networks).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Model Evaluation\n",
    "<!--\n",
    "- Evaluate model performance on validation data.\n",
    "- Use appropriate metrics (e.g., accuracy, precision, recall, RMSE).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Hyperparameter Tuning\n",
    "<!--\n",
    "- Fine-tune the model using techniques like Grid Search or Random Search.\n",
    "- Evaluate the impact of different hyperparameters.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Model Testing\n",
    "<!--\n",
    "- Evaluate the final model on the test dataset.\n",
    "- Ensure that the model generalizes well to unseen data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Model Interpretation (Optional)\n",
    "<!--\n",
    "- Interpret the model results (e.g., feature importance, SHAP values).\n",
    "- Discuss the strengths and limitations of the model.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Make Predictions\n",
    "<!--\n",
    "- Use the trained model to make predictions on new/unseen data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Save Model and Results\n",
    "<!--\n",
    "- Save the trained model to disk for future use.\n",
    "- Export prediction results for further analysis.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Documentation and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Summary of Findings\n",
    "<!--\n",
    "- Summarize the results and findings of the analysis.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Next Steps\n",
    "<!--\n",
    "- Suggest further improvements, alternative models, or future work.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 References\n",
    "<!--\n",
    "- Cite any resources, papers, or documentation used.\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
